from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import Response, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from loguru import logger
from io import BytesIO
from PIL import Image
import pandas as pd
from pandas.errors import ParserError
import numpy as np

# –Ω–∞–π—Ç–∏ —Å–ø–æ—Å–æ–±, –∫–∞–∫ –º–æ–∂–Ω–æ —Å –æ–ø–µ–Ω—Å–æ—Ä—Å–æ–º —Å–∂–∞—Ç—å —Ñ–æ—Ç–æ
# –≤–∞—Ä–∏–∞–Ω—Ç—ã: Pillow, pngquant, OpenCV
from PIL import Image
import io
import tinify 
import io
import json
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from email.mime.text import MIMEText

from generate_daily_statistics import generate_daily_statistics
from generate_weekly_statistics import generate_weekly_statistics
import psutil
import time
import base64
from fastapi.responses import JSONResponse
from fastapi import HTTPException, UploadFile
from datetime import datetime

tinify.key = "Vc1ZzMhvsvNSkbVSzdD7ntP4mqHZV1vP"  # –ó–∞–º–µ–Ω–∏—Ç—å API –∫–ª—é—á

app = FastAPI()

# Optional: CORS settings if needed
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def build_base64_json_response(fig, json_payload: dict) -> JSONResponse:
    # Convert figure to PNG bytes
    img_bytes = fig.to_image(format="png")

    # Compress with TinyPNG
    # source = tinify.from_buffer(img_bytes)
    # compressed_img_bytes = source.to_buffer()
    
    # Pillow compress
    img = Image.open(io.BytesIO(img_bytes))
    buffer = io.BytesIO()

    # img.save(buffer, format="PNG", optimize=True) 
    img.save(buffer, format="WEBP", quality=80)  # –ú–æ–∂–Ω–æ –ø–æ–Ω–∏–∑–∏—Ç—å quality –¥–ª—è —Å–∏–ª—å–Ω–µ–µ —Å–∂–∞—Ç–∏—è

    compressed_img_bytes = buffer.getvalue()

    # Encode image to base64
    encoded_image = base64.b64encode(compressed_img_bytes).decode("utf-8")

    # Add image to payload
    json_payload["image_base64"] = encoded_image

    return JSONResponse(content=json_payload)


def read_csv_safe(file: UploadFile) -> pd.DataFrame:
    try:
        # –ß–∏—Ç–∞–µ–º –≤—Å—ë –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏, –±–µ–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ NaN
        df = pd.read_csv(file, sep=";", dtype=str, keep_default_na=False)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {str(e)}")

    expected_columns = {
        "id": int,
        "date": "datetime",
        "open_card_count": int,
        "add_to_cart_count": int,
        "orders_count": int,
        "orders_sum_rub": int,
        "views": int,
        "cliks": int,
        "sum": float,
    }

    if len(df) < 14:
        raise HTTPException(status_code=400, detail=f"–û–∂–∏–¥–∞–ª–æ—Å—å –º–∏–Ω–∏–º—É–º 14 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞), –ø–æ–ª—É—á–µ–Ω–æ: {len(df)}")

    if list(df.columns) != list(expected_columns.keys()):
        raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–µ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π
    for col, expected_type in expected_columns.items():
        for i, val in enumerate(df[col], start=2):  # +2 –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∑–∞–≥–æ–ª–æ–≤–∫–∏
            try:
                if expected_type == "datetime":
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–≤—ã—á–µ–∫
                    if any(val.startswith(c) and val.endswith(c) for c in ('"', "'", "`")):
                        raise ValueError("–î–∞—Ç–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö")
                    pd.to_datetime(val, format="%Y-%m-%d")
                elif expected_type == int:
                    if any(val.startswith(c) and val.endswith(c) for c in ('"', "'", "`")):
                        raise ValueError("int –≤ –∫–∞–≤—ã—á–∫–∞—Ö")
                    int(val)
                elif expected_type == float:
                    if any(val.startswith(c) and val.endswith(c) for c in ('"', "'", "`")):
                        raise ValueError("float –≤ –∫–∞–≤—ã—á–∫–∞—Ö")
                    float(val)
                else:
                    raise ValueError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø")
            except Exception as e:
                raise HTTPException(
                    status_code=400,
                    detail=f"–°—Ç–æ–ª–±–µ—Ü '{col}', —Å—Ç—Ä–æ–∫–∞ {i}: –∑–Ω–∞—á–µ–Ω–∏–µ '{val}' –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–∏–ø—É {expected_type} ‚Äî {e}"
                )

    return df



@app.post("/get-image-daily")
async def daily_statistics(
    file1: UploadFile = File(...), # ("–∏–º—è_—Ñ–∞–π–ª–∞", —Ñ–∞–π–ª–æ–≤—ã–π_–æ–±—ä–µ–∫—Ç, "MIME-—Ç–∏–ø") - –∫–æ—Ä—Ç–µ–∂ –∏–∑ 3 —á–∞—Å—Ç–µ–π!
    file2: UploadFile = File(...),
    token_id: str = Form(...),
    supplier_id: str = Form(...),
    cabinet_name: str = Form(...),
):
    try:
        logger.info(f"Received files: {file1.filename}, {file2.filename}")

        # —Å—á–∏—Ç—ã–≤–∞–µ–º csv —Å —É—á–µ—Ç–æ–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –æ—à–∏–±–æ–∫ - –µ—Å–ª–∏ –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è, —Ç–æ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç exception 
        df1 = read_csv_safe(file1.file)
        df2 = read_csv_safe(file2.file)

        fig = generate_daily_statistics(df1, df2)

        json_payload = {
            "token_id": token_id,
            "supplier_id": supplier_id,
            "cabinet_name": cabinet_name,
        }

        return build_base64_json_response(fig, json_payload)

    except Exception as e:
        logger.exception("Error generating daily stats")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/get-image-weekly")
async def weekly_statistics(
    file: UploadFile = File(...),
    token_id: str = Form(...),
    supplier_id: str = Form(...),
    cabinet_name: str = Form(...),
):
    try:
        logger.info(f"Received file: {file.filename}")
        df = read_csv_safe(file.file)

        start = time.perf_counter()
        fig = generate_weekly_statistics(df)
        duration = time.perf_counter() - start

        mem = psutil.Process().memory_info().rss / 1024**2
        logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω –∑–∞ {duration:.2f}s, –ø–∞–º—è—Ç—å: {mem:.1f} MB")

        json_payload = {
            "token_id": token_id,
            "supplier_id": supplier_id,
            "cabinet_name": cabinet_name,
        }

        return build_base64_json_response(fig, json_payload)

    except Exception as e:
        logger.exception("Error generating weekly stats")
        return JSONResponse(status_code=500, content={"error": str(e)})
